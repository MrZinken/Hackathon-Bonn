{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# üñºÔ∏è 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erh√§lt einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## üîß Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://github.com/MrZinken/Hackathon-Bonn) runter\n",
    "1. √ñffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Object Detection**\n",
    "4. Klasse: z.‚ÄØB. `baum`, `√ºberdachung`\n",
    "5. Starten und rechts unten Polygon ausw√§hlen\n",
    "6. Flei√üig sein. Alle Objekte der Klasse m√ºssen in dem Bild annotiert werden. Nicht vollst√§ndig annotierte Bilder verschlechtern die Performance signifikant.\n",
    "7. Export: \"Actions\" -> \"Export Annotations\" -> \"Single file in COCO JSON Format\" \n",
    "8. Annotations File umbennen in \"annotations.json\" und zusammen mit den annotierten Bilder in den Ordner datensatz kopieren\n",
    "\n",
    "üëâ Jetzt bitte euren Ordner mit den annotierten Bildern hier per Drag and Drop hochladen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Arbeitsverzeichnis dynamisch zusammensetzen\n",
    "annotations_file = f\"datensatz/annotations.json\"\n",
    "images_dir = f\"datensatz\"\n",
    "\n",
    "# COCO laden mit Fehlerbehandlung\n",
    "try:\n",
    "    coco = COCO(annotations_file)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler beim Laden der COCO-Datei: {e}\")\n",
    "    raise\n",
    "\n",
    "# Bild- und Annotationen-Pr√ºfung\n",
    "missing_files = []\n",
    "invalid_annotations = []\n",
    "\n",
    "print(\"üîç Pr√ºfe Bilder und Annotationen...\")\n",
    "for img in coco.dataset[\"images\"]:\n",
    "    file_path = os.path.join(images_dir, img[\"file_name\"])\n",
    "    if not os.path.isfile(file_path):\n",
    "        missing_files.append(img[\"file_name\"])\n",
    "    \n",
    "    ann_ids = coco.getAnnIds(imgIds=img[\"id\"])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    for ann in anns:\n",
    "        if \"category_id\" not in ann:\n",
    "            invalid_annotations.append({\n",
    "                \"image_file\": img[\"file_name\"],\n",
    "                \"annotation_id\": ann.get(\"id\", \"unknown\"),\n",
    "                \"annotation\": ann\n",
    "            })\n",
    "\n",
    "# Fehlerberichte ausgeben\n",
    "if missing_files:\n",
    "    print(f\"\\n‚ùå Fehlende Bilddateien ({len(missing_files)}):\")\n",
    "    for f in missing_files:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"‚úÖ Alle referenzierten Bilder sind vorhanden.\")\n",
    "\n",
    "if invalid_annotations:\n",
    "    print(f\"\\n‚ùå Annotationen ohne g√ºltige 'category_id' ({len(invalid_annotations)}):\")\n",
    "    for ann in invalid_annotations:\n",
    "        print(f\" - Bild: {ann['image_file']} | Annotation-ID: {ann['annotation_id']} ‚Üí fehlt 'category_id'\")\n",
    "else:\n",
    "    print(\"‚úÖ Alle Annotationen enthalten eine g√ºltige 'category_id'.\")\n",
    "\n",
    "# Falls kritische Fehler: abbrechen\n",
    "if missing_files or invalid_annotations:\n",
    "    print(\"\\n‚ö†Ô∏è Bitte korrigiere die Fehler in deiner JSON-Datei, bevor du weitermachst.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Alles sieht gut aus. Starte Visualisierung...\")\n",
    "\n",
    "    # Erstes Bild anzeigen (optional)\n",
    "    image_ids = coco.getImgIds()\n",
    "    if image_ids:\n",
    "        img_id = image_ids[0]\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "        # Bild laden\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Plot vorbereiten\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Annotations laden\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Maske zeichnen\n",
    "        for ann in anns:\n",
    "            if 'category_id' not in ann:\n",
    "                continue  # Ung√ºltige Annotation √ºberspringen\n",
    "            if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "                for seg in ann['segmentation']:\n",
    "                    poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "                    patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "                    ax.add_patch(patch)\n",
    "\n",
    "        plt.title(img_info['file_name'])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## üìà Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die **Robustheit und Generalisierungsf√§higkeit** des Modells zu verbessern, wurde der urspr√ºngliche Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurden f√ºr jedes bestehende Bild **bis zu zwei zus√§tzliche Varianten** erzeugt. Die Auswahl und Kombination der Augmentierungsschritte erfolgte **zuf√§llig**, jedoch auf Basis definierter Wahrscheinlichkeiten und Begrenzungen.\n",
    "\n",
    "### Eingesetzte Augmentierungsschritte\n",
    "\n",
    "Die folgenden Transformationen wurden mit einer festgelegten Wahrscheinlichkeit pro Bild angewendet:\n",
    "\n",
    "- **Horizontales Spiegeln** (z.‚ÄØB. Dachkanten von links nach rechts gespiegelt)\n",
    "- **Vertikales Spiegeln**\n",
    "- **Zuf√§llige 90¬∞-Rotation** (0¬∞, 90¬∞, 180¬∞ oder 270¬∞)\n",
    "- **Helligkeit und Kontrast**: zuf√§llige √Ñnderung innerhalb von ¬±10‚ÄØ%\n",
    "- **Farbverschiebung (HSV)**:\n",
    "  - **Hue (Farbton)**: ¬±10\n",
    "  - **Saturation (S√§ttigung)**: ¬±10\n",
    "  - **Value (Helligkeit)**: ¬±10\n",
    "\n",
    "Die jeweilige Kombination wurde pro Augmentierungsdurchlauf neu gew√§hlt, sodass **unterschiedliche Transformationen je Bild** m√∂glich sind. Dieser Zufallsfaktor erh√∂ht die Datenvielfalt und minimiert die Gefahr von Overfitting.\n",
    "\n",
    "### Segmentierungs-Masken\n",
    "\n",
    "Die zugeh√∂rigen **Segmentierungsmasken wurden synchron mit den Bildern transformiert**, um die Konsistenz zwischen Bild und Annotation zu erhalten. Dadurch bleiben die semantischen Informationen trotz visueller Ver√§nderung vollst√§ndig erhalten.\n",
    "\n",
    "### Ausgabeformat\n",
    "\n",
    "Die augmentierten Bilder und ihre Annotations wurden im Anschluss gemeinsam mit den Originaldaten in einem **neuen COCO-kompatiblen Datensatz** gespeichert. Dieser kann nahtlos f√ºr Trainingszwecke in Frameworks wie Detectron2, MMDetection oder YOLOv8 weiterverwendet werden.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Erkl√§rung der Augmentierungsparameter\n",
    "\n",
    "| Variable             | Beschreibung                                                         |\n",
    "|----------------------|----------------------------------------------------------------------|\n",
    "| `AUGS_PRO_BILD`      | Anzahl augmentierter Bilder, die pro Original erzeugt werden (z.‚ÄØB. 2) |\n",
    "| `BRIGHTNESS_LIMIT`   | Max. relative Helligkeits√§nderung, z.‚ÄØB. 0.1 = ¬±10‚ÄØ%                 |\n",
    "| `CONTRAST_LIMIT`     | Max. relative Kontrast√§nderung, analog zu `BRIGHTNESS_LIMIT`         |\n",
    "| `HUE_SHIFT`          | Max. Verschiebung des Farbtons (z.‚ÄØB. ¬±10 in HSV-Farbraum)           |\n",
    "| `SAT_SHIFT`          | Max. √Ñnderung der Farbs√§ttigung (z.‚ÄØB. ¬±10)                          |\n",
    "| `VAL_SHIFT`          | Max. √Ñnderung der Helligkeit im HSV-Modell                           |\n",
    "| `p` bei jedem Schritt| Wahrscheinlichkeit, mit der dieser Schritt ausgef√ºhrt wird          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# === üìã EINSTELLUNGEN (ANPASSBARER BEREICH) ===\n",
    "AUGS_PRO_BILD = 2\n",
    "BRIGHTNESS_LIMIT = 0.1\n",
    "CONTRAST_LIMIT = 0.1\n",
    "HUE_SHIFT = 10\n",
    "SAT_SHIFT = 10\n",
    "VAL_SHIFT = 10\n",
    "\n",
    "# === üîÅ AUGMENTIERUNGEN ===\n",
    "AUGMENTATIONS = [\n",
    "    (\"flipH\", lambda: A.HorizontalFlip(p=1.0)),\n",
    "    (\"flipV\", lambda: A.VerticalFlip(p=1.0)),\n",
    "    (\"rot90\", lambda: A.RandomRotate90(p=1.0)),\n",
    "    (\"brightness\", lambda: A.RandomBrightnessContrast(\n",
    "        brightness_limit=BRIGHTNESS_LIMIT,\n",
    "        contrast_limit=CONTRAST_LIMIT,\n",
    "        p=1.0)),\n",
    "    (\"hue\", lambda: A.HueSaturationValue(\n",
    "        hue_shift_limit=HUE_SHIFT,\n",
    "        sat_shift_limit=SAT_SHIFT,\n",
    "        val_shift_limit=VAL_SHIFT,\n",
    "        p=1.0))\n",
    "]\n",
    "\n",
    "# === üìÇ VERZEICHNISSE ===\n",
    "source_dir = \"datensatz\"\n",
    "target_dir = \"datensatz_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# === üìñ JSON LADEN ===\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "extended_data = {\n",
    "    \"images\": list(coco_data[\"images\"]),\n",
    "    \"annotations\": list(coco_data[\"annotations\"]),\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# Originalbilder kopieren\n",
    "for img_entry in coco_data[\"images\"]:\n",
    "    src = os.path.join(source_dir, img_entry[\"file_name\"])\n",
    "    dst = os.path.join(target_dir, img_entry[\"file_name\"])\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "# ID-Offsets\n",
    "next_image_id = max(img[\"id\"] for img in coco_data[\"images\"]) + 1\n",
    "next_ann_id = max(ann[\"id\"] for ann in coco_data[\"annotations\"]) + 1\n",
    "\n",
    "# Zuordnung Bild ‚Üí Annotationen\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# === AUGMENTIERUNG ===\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ö†Ô∏è Fehler beim Laden: {file_name}\")\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    # Bin√§rmasken erzeugen\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    # AUGS_PRO_BILD neue Versionen\n",
    "    for aug_nr in range(AUGS_PRO_BILD):\n",
    "        name, aug_fn = random.choice(AUGMENTATIONS)\n",
    "        transform = A.Compose([aug_fn()])\n",
    "        transformed = transform(image=img, masks=masks)\n",
    "\n",
    "        aug_img = transformed[\"image\"]\n",
    "        aug_masks = transformed[\"masks\"]\n",
    "        new_filename = f\"{name}_{aug_nr}_{file_name}\"\n",
    "        new_path = os.path.join(target_dir, new_filename)\n",
    "        cv2.imwrite(new_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        extended_data[\"images\"].append({\n",
    "            \"id\": next_image_id,\n",
    "            \"file_name\": new_filename,\n",
    "            \"width\": aug_img.shape[1],\n",
    "            \"height\": aug_img.shape[0]\n",
    "        })\n",
    "\n",
    "        for mask in aug_masks:\n",
    "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for contour in contours:\n",
    "                if len(contour) < 3:\n",
    "                    continue\n",
    "                polygon = contour.squeeze().reshape(-1).tolist()\n",
    "                if len(polygon) >= 6:\n",
    "                    bbox = cv2.boundingRect(contour)  # (x, y, w, h)\n",
    "                    area = float(cv2.contourArea(contour))\n",
    "                    extended_data[\"annotations\"].append({\n",
    "                        \"id\": next_ann_id,\n",
    "                        \"image_id\": next_image_id,\n",
    "                        \"category_id\": 1,\n",
    "                        \"segmentation\": [polygon],\n",
    "                        \"area\": area,\n",
    "                        \"bbox\": [bbox[0], bbox[1], bbox[2], bbox[3]],\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    next_ann_id += 1\n",
    "        next_image_id += 1\n",
    "\n",
    "# === SPEICHERN ===\n",
    "out_path = os.path.join(target_dir, \"annotations_augmented.json\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(extended_data, f)\n",
    "\n",
    "print(\"\\n‚úÖ Augmentierung abgeschlossen.\")\n",
    "print(f\"üìÇ Bilder: {target_dir}\")\n",
    "print(f\"üìÑ Annotations: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Pfade\n",
    "json_path = f\"{target_dir}/annotations_augmented.json\"\n",
    "img_dir = target_dir\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(json_path)\n",
    "images = coco.dataset[\"images\"]\n",
    "\n",
    "# üìå Nur augmentierte Bilder ausw√§hlen (z.‚ÄØB. \"flipH_\", \"flipV_\", \"rot90_\")\n",
    "aug_images = [img for img in images if img[\"file_name\"].startswith((\"flip\", \"rot\", \"flipH\", \"flipV\"))]\n",
    "\n",
    "# Den Original-Dateinamen merken ‚Äì angenommen, du wei√üt ihn z.‚ÄØB. von oben:\n",
    "original_file_name = coco.loadImgs(coco.getImgIds()[0])[0][\"file_name\"]\n",
    "\n",
    "# Passendes augmentiertes Bild finden (das denselben Dateinamen am Ende tr√§gt)\n",
    "matched_aug_images = [\n",
    "    img for img in aug_images if img[\"file_name\"].endswith(original_file_name)\n",
    "]\n",
    "\n",
    "if not matched_aug_images:\n",
    "    raise ValueError(f\"‚ùå Kein augmentiertes Bild gefunden, das auf {original_file_name} basiert.\")\n",
    "\n",
    "img_info = matched_aug_images[0]  # Nimm das erste passende\n",
    "\n",
    "img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Masken laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_info[\"id\"])\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "for ann in anns:\n",
    "    seg = ann[\"segmentation\"]\n",
    "    \n",
    "    if isinstance(seg, list):  # Polygon\n",
    "        for s in seg:\n",
    "            poly = np.array(s).reshape((len(s) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "    elif isinstance(seg, dict) and \"counts\" in seg:  # RLE\n",
    "        rle = {\n",
    "            \"counts\": seg[\"counts\"].encode(\"utf-8\"),\n",
    "            \"size\": seg[\"size\"]\n",
    "        }\n",
    "        mask = mask_utils.decode(rle)\n",
    "        ax.contour(mask, colors='red', linewidths=2)\n",
    "\n",
    "ax.set_title(f\"Augmentiertes Bild: {img_info['file_name']}\")\n",
    "ax.axis(\"off\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz pr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# üìñ JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# üîé Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# üîé Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# üîé IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# ‚úÖ Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# üñ®Ô∏è Ergebnis\n",
    "print(\"üìÅ Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"‚úÖ Keine\")\n",
    "print(\"üìÅ Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"‚úÖ Keine\")\n",
    "print(\"üìõ Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"‚úÖ Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2a76",
   "metadata": {},
   "source": [
    "## Datensatz Hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üî¢ Gruppennummer eintragen\n",
    "gruppen_nummer = \"\"  # z.‚ÄØB. \"1\", \"17\", \"60\"\n",
    "\n",
    "# üìÇ Lokaler Ordner mit den exportierten JSONs/Bildern\n",
    "target_dir = f\"datensatz_augmented\"\n",
    "\n",
    "# üåê Ziel: annotierte_daten innerhalb der Gruppenstruktur\n",
    "webdav_base = f\"https://mrzinken.duckdns.org/remote.php/dav/files/hackathon2025/HackathonBonn/Gruppe{gruppen_nummer}/annotierte_daten\"\n",
    "\n",
    "# üîê Zugangsdaten\n",
    "username = \"hackathon2025\"\n",
    "password = \"upload2025\"\n",
    "\n",
    "# üì§ Upload-Schleife\n",
    "for fname in tqdm(os.listdir(target_dir), desc=\"üì§ Upload l√§uft\"):\n",
    "    fpath = os.path.join(target_dir, fname)\n",
    "    if os.path.isfile(fpath):\n",
    "        remote_url = f\"{webdav_base}/{fname}\"\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            r = requests.put(remote_url, data=f, auth=(username, password))\n",
    "        if r.status_code in [200, 201, 204]:\n",
    "            print(f\"‚úÖ Hochgeladen: {fname}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Fehler bei {fname}: {r.status_code} {r.text}\")\n",
    "\n",
    "print(\"üèÅ Upload abgeschlossen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
