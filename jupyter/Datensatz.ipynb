{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# ğŸ–¼ï¸ 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erhÃ¤lt einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## ğŸ”§ Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://databox.bonn.de/public/upload-shares/YhXlVGe57thQAg8WUjVlZFNK6z4LORiq) runter\n",
    "1. Ã–ffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Segmentation**\n",
    "4. Klasse: z.â€¯B. `baum`, `Ã¼berdachung`\n",
    "5. Export: Format `Pascal VOC Segmentation (PNG masks)`\n",
    "\n",
    "ğŸ‘‰ Jetzt bitte eure annotierten Masken und Bilder wieder hochladen. Verwende folgenden Platzhalter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Gruppennummer eintragen\n",
    "gruppen_nummer = 2\n",
    "\n",
    "# Arbeitsverzeichnis dynamisch zusammensetzen\n",
    "annotations_file = f\"datensatz_gruppe{gruppen_nummer}/annotations.json\"\n",
    "images_dir = f\"datensatz_gruppe{gruppen_nummer}\"\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(annotations_file)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Nimm das erste Bild\n",
    "img_id = image_ids[0]\n",
    "img_info = coco.loadImgs(img_id)[0]\n",
    "img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "# Bild laden\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Plot vorbereiten\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Annotations laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Maske zeichnen\n",
    "for ann in anns:\n",
    "    if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "        for seg in ann['segmentation']:\n",
    "            poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "plt.title(img_info['file_name'])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die Robustheit und GeneralisierungsfÃ¤higkeit des Modells zu verbessern, wurde der Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurde zu jedem bestehenden Bild **eine sinnvolle Transformation** erzeugt.\n",
    "\n",
    "Die angewendeten Augmentierungsschritte umfassen:\n",
    "- **Horizontales Spiegeln**\n",
    "- **Leichte Rotation (Â±15Â°)**\n",
    "- **Ã„nderung von Helligkeit und Kontrast**\n",
    "\n",
    "FÃ¼r jedes Originalbild wurde ein neues Bild generiert. Die zugehÃ¶rigen Segmentierungs-Masken wurden dabei korrekt mittransformiert. Die augmentierten Bilder und Masken wurden zusammen mit den Originalen in einer neuen COCO-kompatib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pycocotools import mask as mask_utils\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ğŸ“‚ Verzeichnisse\n",
    "source_dir = images_dir\n",
    "target_dir = f\"datensatz_gruppe{gruppen_nummer}_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# ğŸ“– Originaldaten laden\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# ğŸ§± Neue COCO-Struktur â†’ beginne mit Kopie der Originale\n",
    "extended_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# Kopiere originale Bilder & Ã¼bernehme JSON-EintrÃ¤ge\n",
    "for img_entry in coco_data[\"images\"]:\n",
    "    src_path = os.path.join(source_dir, img_entry[\"file_name\"])\n",
    "    dst_path = os.path.join(target_dir, img_entry[\"file_name\"])\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    extended_data[\"images\"].append(img_entry)\n",
    "\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    extended_data[\"annotations\"].append(ann)\n",
    "\n",
    "# ID-Offsets\n",
    "next_image_id = max(img[\"id\"] for img in coco_data[\"images\"]) + 1\n",
    "next_ann_id = max(ann[\"id\"] for ann in coco_data[\"annotations\"]) + 1\n",
    "\n",
    "# Bild-ID â†’ Annotations\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# âœ… Sichere Augmentierungen\n",
    "aug_choices = [\n",
    "    (\"flipH\", A.HorizontalFlip(p=1.0)),\n",
    "    (\"flipV\", A.VerticalFlip(p=1.0)),\n",
    "    (\"rot90\", A.RandomRotate90(p=1.0))\n",
    "]\n",
    "\n",
    "# Augmentieren\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    aug_name, transform = random.choice(aug_choices)\n",
    "    transformed = transform(image=img, masks=masks)\n",
    "    aug_img = transformed[\"image\"]\n",
    "    aug_masks = transformed[\"masks\"]\n",
    "\n",
    "    new_filename = f\"{aug_name}_{file_name}\"\n",
    "    new_img_path = os.path.join(target_dir, new_filename)\n",
    "    cv2.imwrite(new_img_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    extended_data[\"images\"].append({\n",
    "        \"id\": next_image_id,\n",
    "        \"file_name\": new_filename,\n",
    "        \"width\": aug_img.shape[1],\n",
    "        \"height\": aug_img.shape[0]\n",
    "    })\n",
    "\n",
    "    for mask in aug_masks:\n",
    "        rle = mask_utils.encode(np.asfortranarray(mask.astype(np.uint8)))\n",
    "        area = mask_utils.area(rle).item()\n",
    "        bbox = mask_utils.toBbox(rle).tolist()\n",
    "\n",
    "        seg = mask_utils.encode(np.asfortranarray(mask))\n",
    "        seg[\"counts\"] = seg[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "        extended_data[\"annotations\"].append({\n",
    "            \"id\": next_ann_id,\n",
    "            \"image_id\": next_image_id,\n",
    "            \"category_id\": 1,\n",
    "            \"segmentation\": seg,\n",
    "            \"area\": area,\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": 0\n",
    "        })\n",
    "        next_ann_id += 1\n",
    "\n",
    "    next_image_id += 1\n",
    "\n",
    "# Speichern\n",
    "json_out = os.path.join(target_dir, \"annotations_augmented.json\")\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(extended_data, f)\n",
    "\n",
    "print(f\"âœ… Erweiterung abgeschlossen. Gesamt-Datensatz unter: {target_dir}, JSON: {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Pfade\n",
    "json_path = f\"{target_dir}/annotations_augmented.json\"\n",
    "img_dir = target_dir\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(json_path)\n",
    "images = coco.dataset[\"images\"]\n",
    "\n",
    "# ğŸ“Œ Nur augmentierte Bilder auswÃ¤hlen (z.â€¯B. \"flipH_\", \"flipV_\", \"rot90_\")\n",
    "aug_images = [img for img in images if img[\"file_name\"].startswith((\"flip\", \"rot\", \"flipH\", \"flipV\"))]\n",
    "\n",
    "# Erstes augmentiertes Bild\n",
    "img_info = aug_images[0]\n",
    "img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Masken laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_info[\"id\"])\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "for ann in anns:\n",
    "    seg = ann[\"segmentation\"]\n",
    "    \n",
    "    if isinstance(seg, list):  # Polygon\n",
    "        for s in seg:\n",
    "            poly = np.array(s).reshape((len(s) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "    elif isinstance(seg, dict) and \"counts\" in seg:  # RLE\n",
    "        rle = {\n",
    "            \"counts\": seg[\"counts\"].encode(\"utf-8\"),\n",
    "            \"size\": seg[\"size\"]\n",
    "        }\n",
    "        mask = mask_utils.decode(rle)\n",
    "        ax.contour(mask, colors='red', linewidths=2)\n",
    "\n",
    "ax.set_title(f\"Augmentiertes Bild: {img_info['file_name']}\")\n",
    "ax.axis(\"off\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz prÃ¼fen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# ğŸ“– JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ğŸ” Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# ğŸ” Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# ğŸ” IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# âœ… Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# ğŸ–¨ï¸ Ergebnis\n",
    "print(\"ğŸ“ Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"âœ… Keine\")\n",
    "print(\"ğŸ“ Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"âœ… Keine\")\n",
    "print(\"ğŸ“› Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"âœ… Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2a76",
   "metadata": {},
   "source": [
    "## Datensatz Hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "target_dir = f\"datensatz_gruppe{gruppen_nummer}_augmented\"\n",
    "\n",
    "# ğŸŒ WebDAV-Ziel ohne abschlieÃŸenden Slash!\n",
    "webdav_base = f\"https://mrzinken.duckdns.org/remote.php/dav/files/hackathon2025/HackathonBonn/gruppe{gruppen_nummer}\"\n",
    "\n",
    "# ğŸ” Zugangsdaten\n",
    "username = \"hackathon2025\"\n",
    "password = getpass(\"ğŸ”‘ Passwort eingeben:\")\n",
    "\n",
    "# ğŸ“¤ Upload-Schleife\n",
    "for fname in tqdm(os.listdir(target_dir), desc=\"ğŸ“¤ Upload lÃ¤uft\"):\n",
    "    fpath = os.path.join(target_dir, fname)\n",
    "    if os.path.isfile(fpath):\n",
    "        remote_url = f\"{webdav_base}/{fname}\"\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            r = requests.put(remote_url, data=f, auth=(username, password))\n",
    "        if r.status_code in [200, 201, 204]:\n",
    "            print(f\"âœ… Hochgeladen: {fname}\")\n",
    "        else:\n",
    "            print(f\"âŒ Fehler bei {fname}: {r.status_code} {r.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
