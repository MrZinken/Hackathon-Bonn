{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# 🖼️ 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erhält einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## 🔧 Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://github.com/MrZinken/Hackathon-Bonn) runter\n",
    "1. Öffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Object Detection**\n",
    "4. Klasse: z. B. `baum`, `überdachung`\n",
    "5. Starten und rechts unten Polygon auswählen\n",
    "6. Fleißig sein. Alle Objekte der Klasse müssen in dem Bild annotiert werden. Nicht vollständig annotierte Bilder verschlechtern die Performance signifikant.\n",
    "7. Export: \"Actions\" -> \"Export Annotations\" -> \"Single file in COCO JSON Format\" \n",
    "8. Annotations File umbennen in \"annotations.json\" und zusammen mit den annotierten Bilder in den Ordner datensatz kopieren\n",
    "\n",
    "👉 Jetzt bitte euren Ordner mit den annotierten Bildern hier per Drag and Drop hochladen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/kai/Documents/Hackathon-Bonn/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# Gruppennummer eintragen (Pflicht!)\n",
    "gruppen_nummer = X  # <--- HIER EINTRAGEN!\n",
    "\n",
    "# Check: Gruppennummer muss gesetzt und gültig sein\n",
    "if not isinstance(gruppen_nummer, int) or gruppen_nummer <= 0:\n",
    "    raise ValueError(\"❌ Bitte trage eine gültige Gruppennummer ein (z. B. gruppen_nummer = 61)\")\n",
    "else:\n",
    "    print(f\"👥 Gruppennummer erkannt: {gruppen_nummer}\")\n",
    "\n",
    "\n",
    "# Arbeitsverzeichnis dynamisch zusammensetzen\n",
    "annotations_file = f\"datensatz/annotations.json\"\n",
    "images_dir = f\"datensatz\"\n",
    "\n",
    "# COCO laden mit Fehlerbehandlung\n",
    "try:\n",
    "    coco = COCO(annotations_file)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Fehler beim Laden der COCO-Datei: {e}\")\n",
    "    raise\n",
    "\n",
    "# Bild- und Annotationen-Prüfung\n",
    "missing_files = []\n",
    "invalid_annotations = []\n",
    "\n",
    "print(\"🔍 Prüfe Bilder und Annotationen...\")\n",
    "for img in coco.dataset[\"images\"]:\n",
    "    file_path = os.path.join(images_dir, img[\"file_name\"])\n",
    "    if not os.path.isfile(file_path):\n",
    "        missing_files.append(img[\"file_name\"])\n",
    "    \n",
    "    ann_ids = coco.getAnnIds(imgIds=img[\"id\"])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    for ann in anns:\n",
    "        if \"category_id\" not in ann:\n",
    "            invalid_annotations.append({\n",
    "                \"image_file\": img[\"file_name\"],\n",
    "                \"annotation_id\": ann.get(\"id\", \"unknown\"),\n",
    "                \"annotation\": ann\n",
    "            })\n",
    "\n",
    "# Fehlerberichte ausgeben\n",
    "if missing_files:\n",
    "    print(f\"\\n❌ Fehlende Bilddateien ({len(missing_files)}):\")\n",
    "    for f in missing_files:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"✅ Alle referenzierten Bilder sind vorhanden.\")\n",
    "\n",
    "if invalid_annotations:\n",
    "    print(f\"\\n❌ Annotationen ohne gültige 'category_id' ({len(invalid_annotations)}):\")\n",
    "    for ann in invalid_annotations:\n",
    "        print(f\" - Bild: {ann['image_file']} | Annotation-ID: {ann['annotation_id']} → fehlt 'category_id'\")\n",
    "else:\n",
    "    print(\"✅ Alle Annotationen enthalten eine gültige 'category_id'.\")\n",
    "\n",
    "# Falls kritische Fehler: abbrechen\n",
    "if missing_files or invalid_annotations:\n",
    "    print(\"\\n⚠️ Bitte korrigiere die Fehler in deiner JSON-Datei, bevor du weitermachst.\")\n",
    "else:\n",
    "    print(\"\\n✅ Alles sieht gut aus. Starte Visualisierung...\")\n",
    "\n",
    "    # Erstes Bild anzeigen (optional)\n",
    "    image_ids = coco.getImgIds()\n",
    "    if image_ids:\n",
    "        img_id = image_ids[0]\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "        # Bild laden\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Plot vorbereiten\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Annotations laden\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Maske zeichnen\n",
    "        for ann in anns:\n",
    "            if 'category_id' not in ann:\n",
    "                continue  # Ungültige Annotation überspringen\n",
    "            if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "                for seg in ann['segmentation']:\n",
    "                    poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "                    patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "                    ax.add_patch(patch)\n",
    "\n",
    "        plt.title(img_info['file_name'])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## 📈 Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die **Robustheit und Generalisierungsfähigkeit** des Modells zu verbessern, wurde der ursprüngliche Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurden für jedes bestehende Bild **bis zu zwei zusätzliche Varianten** erzeugt. Die Auswahl und Kombination der Augmentierungsschritte erfolgte **zufällig**, jedoch auf Basis definierter Wahrscheinlichkeiten und Begrenzungen.\n",
    "\n",
    "### Eingesetzte Augmentierungsschritte\n",
    "\n",
    "Die folgenden Transformationen wurden mit einer festgelegten Wahrscheinlichkeit pro Bild angewendet:\n",
    "\n",
    "- **Horizontales Spiegeln** (z. B. Dachkanten von links nach rechts gespiegelt)\n",
    "- **Vertikales Spiegeln**\n",
    "- **Zufällige 90°-Rotation** (0°, 90°, 180° oder 270°)\n",
    "- **Helligkeit und Kontrast**: zufällige Änderung innerhalb von ±10 %\n",
    "- **Farbverschiebung (HSV)**:\n",
    "  - **Hue (Farbton)**: ±10\n",
    "  - **Saturation (Sättigung)**: ±10\n",
    "  - **Value (Helligkeit)**: ±10\n",
    "\n",
    "Die jeweilige Kombination wurde pro Augmentierungsdurchlauf neu gewählt, sodass **unterschiedliche Transformationen je Bild** möglich sind. Dieser Zufallsfaktor erhöht die Datenvielfalt und minimiert die Gefahr von Overfitting.\n",
    "\n",
    "### Segmentierungs-Masken\n",
    "\n",
    "Die zugehörigen **Segmentierungsmasken wurden synchron mit den Bildern transformiert**, um die Konsistenz zwischen Bild und Annotation zu erhalten. Dadurch bleiben die semantischen Informationen trotz visueller Veränderung vollständig erhalten.\n",
    "\n",
    "### Ausgabeformat\n",
    "\n",
    "Die augmentierten Bilder und ihre Annotations wurden im Anschluss gemeinsam mit den Originaldaten in einem **neuen COCO-kompatiblen Datensatz** gespeichert. Dieser kann nahtlos für Trainingszwecke in Frameworks wie Detectron2, MMDetection oder YOLOv8 weiterverwendet werden.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Erklärung der Augmentierungsparameter\n",
    "\n",
    "| Variable             | Beschreibung                                                         |\n",
    "|----------------------|----------------------------------------------------------------------|\n",
    "| `AUGS_PRO_BILD`      | Anzahl augmentierter Bilder, die pro Original erzeugt werden (z. B. 2) |\n",
    "| `BRIGHTNESS_LIMIT`   | Max. relative Helligkeitsänderung, z. B. 0.1 = ±10 %                 |\n",
    "| `CONTRAST_LIMIT`     | Max. relative Kontraständerung, analog zu `BRIGHTNESS_LIMIT`         |\n",
    "| `HUE_SHIFT`          | Max. Verschiebung des Farbtons (z. B. ±10 in HSV-Farbraum)           |\n",
    "| `SAT_SHIFT`          | Max. Änderung der Farbsättigung (z. B. ±10)                          |\n",
    "| `VAL_SHIFT`          | Max. Änderung der Helligkeit im HSV-Modell                           |\n",
    "| `p` bei jedem Schritt| Wahrscheinlichkeit, mit der dieser Schritt ausgeführt wird          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pycocotools import mask as mask_utils\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# === 📋 EINSTELLUNGEN ===\n",
    "\n",
    "# Wie viele augmentierte Bilder pro Originalbild erzeugen?\n",
    "AUGS_PRO_BILD = 2\n",
    "\n",
    "# Maximale Veränderung (±) bei Helligkeit & Kontrast in Prozent (0.1 = ±10%)\n",
    "BRIGHTNESS_LIMIT = 0.1\n",
    "CONTRAST_LIMIT = 0.1\n",
    "\n",
    "# Farbverschiebung (max. Veränderung in absoluten Werten für H, S, V)\n",
    "HUE_SHIFT = 10         # max ±10 Farbton\n",
    "SAT_SHIFT = 10         # max ±10 Sättigung\n",
    "VAL_SHIFT = 10         # max ±10 Helligkeit\n",
    "\n",
    "# === 🔁 AUGMENTIERUNGEN MIT WAHRSCHEINLICHKEITEN ===\n",
    "AUGMENTATIONS = [\n",
    "    (\"flipH\", A.HorizontalFlip(p=0.5)),\n",
    "    (\"flipV\", A.VerticalFlip(p=0.5)),\n",
    "    (\"rot90\", A.RandomRotate90(p=0.3)),\n",
    "    (\"brightness\", A.RandomBrightnessContrast(\n",
    "        brightness_limit=BRIGHTNESS_LIMIT,\n",
    "        contrast_limit=CONTRAST_LIMIT,\n",
    "        p=0.4)),\n",
    "    (\"hue\", A.HueSaturationValue(\n",
    "        hue_shift_limit=HUE_SHIFT,\n",
    "        sat_shift_limit=SAT_SHIFT,\n",
    "        val_shift_limit=VAL_SHIFT,\n",
    "        p=0.2))\n",
    "]\n",
    "\n",
    "# === 📂 VERZEICHNISSE ===\n",
    "source_dir = \"datensatz\"\n",
    "target_dir = \"datensatz_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# === 📖 JSON LADEN ===\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Neue COCO-Struktur\n",
    "extended_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# Originalbilder kopieren\n",
    "for img_entry in coco_data[\"images\"]:\n",
    "    src_path = os.path.join(source_dir, img_entry[\"file_name\"])\n",
    "    dst_path = os.path.join(target_dir, img_entry[\"file_name\"])\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    extended_data[\"images\"].append(img_entry)\n",
    "\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    extended_data[\"annotations\"].append(ann)\n",
    "\n",
    "# ID-Offsets berechnen\n",
    "next_image_id = max(img[\"id\"] for img in coco_data[\"images\"]) + 1\n",
    "next_ann_id = max(ann[\"id\"] for ann in coco_data[\"annotations\"]) + 1\n",
    "\n",
    "# Bild-ID zu Annotationen mappen\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# === 🚀 AUGMENTIERUNG ===\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Bild nicht lesbar: {file_name}\")\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    # Maske generieren\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    for aug_nr in range(AUGS_PRO_BILD):\n",
    "        selected_transforms = []\n",
    "        aug_names = []\n",
    "\n",
    "        for name, aug in AUGMENTATIONS:\n",
    "            if random.random() < aug.p:  # Zufällige Auswahl auf Basis der Wahrscheinlichkeit\n",
    "                selected_transforms.append(aug)\n",
    "                aug_names.append(name)\n",
    "\n",
    "        if not selected_transforms:\n",
    "            continue  # Wenn keine Transformation ausgewählt wurde, überspringen\n",
    "\n",
    "        composed = A.Compose(selected_transforms)\n",
    "        transformed = composed(image=img, masks=masks)\n",
    "        aug_img = transformed[\"image\"]\n",
    "        aug_masks = transformed[\"masks\"]\n",
    "\n",
    "        new_filename = f\"{'_'.join(aug_names)}_{aug_nr}_{file_name}\"\n",
    "        new_img_path = os.path.join(target_dir, new_filename)\n",
    "        cv2.imwrite(new_img_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        extended_data[\"images\"].append({\n",
    "            \"id\": next_image_id,\n",
    "            \"file_name\": new_filename,\n",
    "            \"width\": aug_img.shape[1],\n",
    "            \"height\": aug_img.shape[0]\n",
    "        })\n",
    "\n",
    "        for mask in aug_masks:\n",
    "            rle = mask_utils.encode(np.asfortranarray(mask.astype(np.uint8)))\n",
    "            area = mask_utils.area(rle).item()\n",
    "            bbox = mask_utils.toBbox(rle).tolist()\n",
    "\n",
    "            seg = mask_utils.encode(np.asfortranarray(mask))\n",
    "            seg[\"counts\"] = seg[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "            extended_data[\"annotations\"].append({\n",
    "                \"id\": next_ann_id,\n",
    "                \"image_id\": next_image_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": seg,\n",
    "                \"area\": area,\n",
    "                \"bbox\": bbox,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            next_ann_id += 1\n",
    "\n",
    "        next_image_id += 1\n",
    "\n",
    "# === 💾 SPEICHERN ===\n",
    "json_out = os.path.join(target_dir, \"annotations_augmented.json\")\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(extended_data, f)\n",
    "\n",
    "print(f\"\\n✅ Augmentierung abgeschlossen.\")\n",
    "print(f\"📂 Neue Bilder liegen in: {target_dir}\")\n",
    "print(f\"📄 Neue COCO-Annotations unter: {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Pfade\n",
    "json_path = f\"{target_dir}/annotations_augmented.json\"\n",
    "img_dir = target_dir\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(json_path)\n",
    "images = coco.dataset[\"images\"]\n",
    "\n",
    "# 📌 Nur augmentierte Bilder auswählen (z. B. \"flipH_\", \"flipV_\", \"rot90_\")\n",
    "aug_images = [img for img in images if img[\"file_name\"].startswith((\"flip\", \"rot\", \"flipH\", \"flipV\"))]\n",
    "\n",
    "# Erstes augmentiertes Bild\n",
    "img_info = aug_images[0]\n",
    "img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Masken laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_info[\"id\"])\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "for ann in anns:\n",
    "    seg = ann[\"segmentation\"]\n",
    "    \n",
    "    if isinstance(seg, list):  # Polygon\n",
    "        for s in seg:\n",
    "            poly = np.array(s).reshape((len(s) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "    elif isinstance(seg, dict) and \"counts\" in seg:  # RLE\n",
    "        rle = {\n",
    "            \"counts\": seg[\"counts\"].encode(\"utf-8\"),\n",
    "            \"size\": seg[\"size\"]\n",
    "        }\n",
    "        mask = mask_utils.decode(rle)\n",
    "        ax.contour(mask, colors='red', linewidths=2)\n",
    "\n",
    "ax.set_title(f\"Augmentiertes Bild: {img_info['file_name']}\")\n",
    "ax.axis(\"off\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# 📖 JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 🔎 Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# 🔎 Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# 🔎 IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# ✅ Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# 🖨️ Ergebnis\n",
    "print(\"📁 Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"✅ Keine\")\n",
    "print(\"📁 Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"✅ Keine\")\n",
    "print(\"📛 Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"✅ Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2a76",
   "metadata": {},
   "source": [
    "## Datensatz Hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 🔢 Gruppennummer eintragen\n",
    "gruppen_nummer = \"60\"  # z. B. \"01\", \"17\", \"60\"\n",
    "\n",
    "# 📂 Lokaler Ordner mit den exportierten JSONs/Bildern\n",
    "target_dir = f\"datensatz_augmented\"\n",
    "\n",
    "# 🌐 Ziel: annotierte_daten innerhalb der Gruppenstruktur\n",
    "webdav_base = f\"https://mrzinken.duckdns.org/remote.php/dav/files/hackathon2025/HackathonBonn/Gruppe{gruppen_nummer}/annotierte_daten\"\n",
    "\n",
    "# 🔐 Zugangsdaten\n",
    "username = \"hackathon2025\"\n",
    "password = \"upload2025\"\n",
    "\n",
    "# 📤 Upload-Schleife\n",
    "for fname in tqdm(os.listdir(target_dir), desc=\"📤 Upload läuft\"):\n",
    "    fpath = os.path.join(target_dir, fname)\n",
    "    if os.path.isfile(fpath):\n",
    "        remote_url = f\"{webdav_base}/{fname}\"\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            r = requests.put(remote_url, data=f, auth=(username, password))\n",
    "        if r.status_code in [200, 201, 204]:\n",
    "            print(f\"✅ Hochgeladen: {fname}\")\n",
    "        else:\n",
    "            print(f\"❌ Fehler bei {fname}: {r.status_code} {r.text}\")\n",
    "\n",
    "print(\"🏁 Upload abgeschlossen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
