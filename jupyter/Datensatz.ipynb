{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# ðŸ–¼ï¸ 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erhÃ¤lt einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## ðŸ”§ Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://github.com/MrZinken/Hackathon-Bonn) runter\n",
    "1. Ã–ffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Object Detection**\n",
    "4. Klasse: z.â€¯B. `baum`, `Ã¼berdachung`\n",
    "5. Starten und rechts unten Polygon auswÃ¤hlen\n",
    "6. FleiÃŸig sein. Alle Objekte der Klasse mÃ¼ssen in dem Bild annotiert werden. Nicht vollstÃ¤ndig annotierte Bilder verschlechtern die Performance signifikant.\n",
    "7. Export: \"Actions\" -> \"Export Annotations\" -> \"Single file in COCO JSON Format\" \n",
    "8. Annotations File umbennen in \"annotations.json\" und zusammen mit den annotierten Bilder in den Ordner datensatz kopieren\n",
    "\n",
    "ðŸ‘‰ Jetzt bitte euren Ordner mit den annotierten Bildern hier per Drag and Drop hochladen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/kai/Documents/Hackathon-Bonn/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# Gruppennummer eintragen (Pflicht!)\n",
    "gruppen_nummer = X  # <--- HIER EINTRAGEN!\n",
    "\n",
    "# Check: Gruppennummer muss gesetzt und gÃ¼ltig sein\n",
    "if not isinstance(gruppen_nummer, int) or gruppen_nummer <= 0:\n",
    "    raise ValueError(\"âŒ Bitte trage eine gÃ¼ltige Gruppennummer ein (z.â€¯B. gruppen_nummer = 61)\")\n",
    "else:\n",
    "    print(f\"ðŸ‘¥ Gruppennummer erkannt: {gruppen_nummer}\")\n",
    "\n",
    "\n",
    "# Arbeitsverzeichnis dynamisch zusammensetzen\n",
    "annotations_file = f\"datensatz/annotations.json\"\n",
    "images_dir = f\"datensatz\"\n",
    "\n",
    "# COCO laden mit Fehlerbehandlung\n",
    "try:\n",
    "    coco = COCO(annotations_file)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Fehler beim Laden der COCO-Datei: {e}\")\n",
    "    raise\n",
    "\n",
    "# Bild- und Annotationen-PrÃ¼fung\n",
    "missing_files = []\n",
    "invalid_annotations = []\n",
    "\n",
    "print(\"ðŸ” PrÃ¼fe Bilder und Annotationen...\")\n",
    "for img in coco.dataset[\"images\"]:\n",
    "    file_path = os.path.join(images_dir, img[\"file_name\"])\n",
    "    if not os.path.isfile(file_path):\n",
    "        missing_files.append(img[\"file_name\"])\n",
    "    \n",
    "    ann_ids = coco.getAnnIds(imgIds=img[\"id\"])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    for ann in anns:\n",
    "        if \"category_id\" not in ann:\n",
    "            invalid_annotations.append({\n",
    "                \"image_file\": img[\"file_name\"],\n",
    "                \"annotation_id\": ann.get(\"id\", \"unknown\"),\n",
    "                \"annotation\": ann\n",
    "            })\n",
    "\n",
    "# Fehlerberichte ausgeben\n",
    "if missing_files:\n",
    "    print(f\"\\nâŒ Fehlende Bilddateien ({len(missing_files)}):\")\n",
    "    for f in missing_files:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"âœ… Alle referenzierten Bilder sind vorhanden.\")\n",
    "\n",
    "if invalid_annotations:\n",
    "    print(f\"\\nâŒ Annotationen ohne gÃ¼ltige 'category_id' ({len(invalid_annotations)}):\")\n",
    "    for ann in invalid_annotations:\n",
    "        print(f\" - Bild: {ann['image_file']} | Annotation-ID: {ann['annotation_id']} â†’ fehlt 'category_id'\")\n",
    "else:\n",
    "    print(\"âœ… Alle Annotationen enthalten eine gÃ¼ltige 'category_id'.\")\n",
    "\n",
    "# Falls kritische Fehler: abbrechen\n",
    "if missing_files or invalid_annotations:\n",
    "    print(\"\\nâš ï¸ Bitte korrigiere die Fehler in deiner JSON-Datei, bevor du weitermachst.\")\n",
    "else:\n",
    "    print(\"\\nâœ… Alles sieht gut aus. Starte Visualisierung...\")\n",
    "\n",
    "    # Erstes Bild anzeigen (optional)\n",
    "    image_ids = coco.getImgIds()\n",
    "    if image_ids:\n",
    "        img_id = image_ids[0]\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "        # Bild laden\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        # Plot vorbereiten\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Annotations laden\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Maske zeichnen\n",
    "        for ann in anns:\n",
    "            if 'category_id' not in ann:\n",
    "                continue  # UngÃ¼ltige Annotation Ã¼berspringen\n",
    "            if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "                for seg in ann['segmentation']:\n",
    "                    poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "                    patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "                    ax.add_patch(patch)\n",
    "\n",
    "        plt.title(img_info['file_name'])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die **Robustheit und GeneralisierungsfÃ¤higkeit** des Modells zu verbessern, wurde der ursprÃ¼ngliche Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurden fÃ¼r jedes bestehende Bild **bis zu zwei zusÃ¤tzliche Varianten** erzeugt. Die Auswahl und Kombination der Augmentierungsschritte erfolgte **zufÃ¤llig**, jedoch auf Basis definierter Wahrscheinlichkeiten und Begrenzungen.\n",
    "\n",
    "### Eingesetzte Augmentierungsschritte\n",
    "\n",
    "Die folgenden Transformationen wurden mit einer festgelegten Wahrscheinlichkeit pro Bild angewendet:\n",
    "\n",
    "- **Horizontales Spiegeln** (z.â€¯B. Dachkanten von links nach rechts gespiegelt)\n",
    "- **Vertikales Spiegeln**\n",
    "- **ZufÃ¤llige 90Â°-Rotation** (0Â°, 90Â°, 180Â° oder 270Â°)\n",
    "- **Helligkeit und Kontrast**: zufÃ¤llige Ã„nderung innerhalb von Â±10â€¯%\n",
    "- **Farbverschiebung (HSV)**:\n",
    "  - **Hue (Farbton)**: Â±10\n",
    "  - **Saturation (SÃ¤ttigung)**: Â±10\n",
    "  - **Value (Helligkeit)**: Â±10\n",
    "\n",
    "Die jeweilige Kombination wurde pro Augmentierungsdurchlauf neu gewÃ¤hlt, sodass **unterschiedliche Transformationen je Bild** mÃ¶glich sind. Dieser Zufallsfaktor erhÃ¶ht die Datenvielfalt und minimiert die Gefahr von Overfitting.\n",
    "\n",
    "### Segmentierungs-Masken\n",
    "\n",
    "Die zugehÃ¶rigen **Segmentierungsmasken wurden synchron mit den Bildern transformiert**, um die Konsistenz zwischen Bild und Annotation zu erhalten. Dadurch bleiben die semantischen Informationen trotz visueller VerÃ¤nderung vollstÃ¤ndig erhalten.\n",
    "\n",
    "### Ausgabeformat\n",
    "\n",
    "Die augmentierten Bilder und ihre Annotations wurden im Anschluss gemeinsam mit den Originaldaten in einem **neuen COCO-kompatiblen Datensatz** gespeichert. Dieser kann nahtlos fÃ¼r Trainingszwecke in Frameworks wie Detectron2, MMDetection oder YOLOv8 weiterverwendet werden.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ ErklÃ¤rung der Augmentierungsparameter\n",
    "\n",
    "| Variable             | Beschreibung                                                         |\n",
    "|----------------------|----------------------------------------------------------------------|\n",
    "| `AUGS_PRO_BILD`      | Anzahl augmentierter Bilder, die pro Original erzeugt werden (z.â€¯B. 2) |\n",
    "| `BRIGHTNESS_LIMIT`   | Max. relative HelligkeitsÃ¤nderung, z.â€¯B. 0.1 = Â±10â€¯%                 |\n",
    "| `CONTRAST_LIMIT`     | Max. relative KontrastÃ¤nderung, analog zu `BRIGHTNESS_LIMIT`         |\n",
    "| `HUE_SHIFT`          | Max. Verschiebung des Farbtons (z.â€¯B. Â±10 in HSV-Farbraum)           |\n",
    "| `SAT_SHIFT`          | Max. Ã„nderung der FarbsÃ¤ttigung (z.â€¯B. Â±10)                          |\n",
    "| `VAL_SHIFT`          | Max. Ã„nderung der Helligkeit im HSV-Modell                           |\n",
    "| `p` bei jedem Schritt| Wahrscheinlichkeit, mit der dieser Schritt ausgefÃ¼hrt wird          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pycocotools import mask as mask_utils\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# === ðŸ“‹ EINSTELLUNGEN ===\n",
    "\n",
    "# Wie viele augmentierte Bilder pro Originalbild erzeugen?\n",
    "AUGS_PRO_BILD = 2\n",
    "\n",
    "# Maximale VerÃ¤nderung (Â±) bei Helligkeit & Kontrast in Prozent (0.1 = Â±10%)\n",
    "BRIGHTNESS_LIMIT = 0.1\n",
    "CONTRAST_LIMIT = 0.1\n",
    "\n",
    "# Farbverschiebung (max. VerÃ¤nderung in absoluten Werten fÃ¼r H, S, V)\n",
    "HUE_SHIFT = 10         # max Â±10 Farbton\n",
    "SAT_SHIFT = 10         # max Â±10 SÃ¤ttigung\n",
    "VAL_SHIFT = 10         # max Â±10 Helligkeit\n",
    "\n",
    "# === ðŸ” AUGMENTIERUNGEN MIT WAHRSCHEINLICHKEITEN ===\n",
    "AUGMENTATIONS = [\n",
    "    (\"flipH\", A.HorizontalFlip(p=0.5)),\n",
    "    (\"flipV\", A.VerticalFlip(p=0.5)),\n",
    "    (\"rot90\", A.RandomRotate90(p=0.3)),\n",
    "    (\"brightness\", A.RandomBrightnessContrast(\n",
    "        brightness_limit=BRIGHTNESS_LIMIT,\n",
    "        contrast_limit=CONTRAST_LIMIT,\n",
    "        p=0.4)),\n",
    "    (\"hue\", A.HueSaturationValue(\n",
    "        hue_shift_limit=HUE_SHIFT,\n",
    "        sat_shift_limit=SAT_SHIFT,\n",
    "        val_shift_limit=VAL_SHIFT,\n",
    "        p=0.2))\n",
    "]\n",
    "\n",
    "# === ðŸ“‚ VERZEICHNISSE ===\n",
    "source_dir = \"datensatz\"\n",
    "target_dir = \"datensatz_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# === ðŸ“– JSON LADEN ===\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Neue COCO-Struktur\n",
    "extended_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# Originalbilder kopieren\n",
    "for img_entry in coco_data[\"images\"]:\n",
    "    src_path = os.path.join(source_dir, img_entry[\"file_name\"])\n",
    "    dst_path = os.path.join(target_dir, img_entry[\"file_name\"])\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    extended_data[\"images\"].append(img_entry)\n",
    "\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    extended_data[\"annotations\"].append(ann)\n",
    "\n",
    "# ID-Offsets berechnen\n",
    "next_image_id = max(img[\"id\"] for img in coco_data[\"images\"]) + 1\n",
    "next_ann_id = max(ann[\"id\"] for ann in coco_data[\"annotations\"]) + 1\n",
    "\n",
    "# Bild-ID zu Annotationen mappen\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# === ðŸš€ AUGMENTIERUNG ===\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"âš ï¸ Bild nicht lesbar: {file_name}\")\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    # Maske generieren\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    for aug_nr in range(AUGS_PRO_BILD):\n",
    "        selected_transforms = []\n",
    "        aug_names = []\n",
    "\n",
    "        for name, aug in AUGMENTATIONS:\n",
    "            if random.random() < aug.p:  # ZufÃ¤llige Auswahl auf Basis der Wahrscheinlichkeit\n",
    "                selected_transforms.append(aug)\n",
    "                aug_names.append(name)\n",
    "\n",
    "        if not selected_transforms:\n",
    "            continue  # Wenn keine Transformation ausgewÃ¤hlt wurde, Ã¼berspringen\n",
    "\n",
    "        composed = A.Compose(selected_transforms)\n",
    "        transformed = composed(image=img, masks=masks)\n",
    "        aug_img = transformed[\"image\"]\n",
    "        aug_masks = transformed[\"masks\"]\n",
    "\n",
    "        new_filename = f\"{'_'.join(aug_names)}_{aug_nr}_{file_name}\"\n",
    "        new_img_path = os.path.join(target_dir, new_filename)\n",
    "        cv2.imwrite(new_img_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        extended_data[\"images\"].append({\n",
    "            \"id\": next_image_id,\n",
    "            \"file_name\": new_filename,\n",
    "            \"width\": aug_img.shape[1],\n",
    "            \"height\": aug_img.shape[0]\n",
    "        })\n",
    "\n",
    "        for mask in aug_masks:\n",
    "            rle = mask_utils.encode(np.asfortranarray(mask.astype(np.uint8)))\n",
    "            area = mask_utils.area(rle).item()\n",
    "            bbox = mask_utils.toBbox(rle).tolist()\n",
    "\n",
    "            seg = mask_utils.encode(np.asfortranarray(mask))\n",
    "            seg[\"counts\"] = seg[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "            extended_data[\"annotations\"].append({\n",
    "                \"id\": next_ann_id,\n",
    "                \"image_id\": next_image_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": seg,\n",
    "                \"area\": area,\n",
    "                \"bbox\": bbox,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            next_ann_id += 1\n",
    "\n",
    "        next_image_id += 1\n",
    "\n",
    "# === ðŸ’¾ SPEICHERN ===\n",
    "json_out = os.path.join(target_dir, \"annotations_augmented.json\")\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(extended_data, f)\n",
    "\n",
    "print(f\"\\nâœ… Augmentierung abgeschlossen.\")\n",
    "print(f\"ðŸ“‚ Neue Bilder liegen in: {target_dir}\")\n",
    "print(f\"ðŸ“„ Neue COCO-Annotations unter: {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Pfade\n",
    "json_path = f\"{target_dir}/annotations_augmented.json\"\n",
    "img_dir = target_dir\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(json_path)\n",
    "images = coco.dataset[\"images\"]\n",
    "\n",
    "# ðŸ“Œ Nur augmentierte Bilder auswÃ¤hlen (z.â€¯B. \"flipH_\", \"flipV_\", \"rot90_\")\n",
    "aug_images = [img for img in images if img[\"file_name\"].startswith((\"flip\", \"rot\", \"flipH\", \"flipV\"))]\n",
    "\n",
    "# Erstes augmentiertes Bild\n",
    "img_info = aug_images[0]\n",
    "img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Masken laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_info[\"id\"])\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "for ann in anns:\n",
    "    seg = ann[\"segmentation\"]\n",
    "    \n",
    "    if isinstance(seg, list):  # Polygon\n",
    "        for s in seg:\n",
    "            poly = np.array(s).reshape((len(s) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "    elif isinstance(seg, dict) and \"counts\" in seg:  # RLE\n",
    "        rle = {\n",
    "            \"counts\": seg[\"counts\"].encode(\"utf-8\"),\n",
    "            \"size\": seg[\"size\"]\n",
    "        }\n",
    "        mask = mask_utils.decode(rle)\n",
    "        ax.contour(mask, colors='red', linewidths=2)\n",
    "\n",
    "ax.set_title(f\"Augmentiertes Bild: {img_info['file_name']}\")\n",
    "ax.axis(\"off\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz prÃ¼fen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# ðŸ“– JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ðŸ”Ž Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# ðŸ”Ž Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# ðŸ”Ž IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# âœ… Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# ðŸ–¨ï¸ Ergebnis\n",
    "print(\"ðŸ“ Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"âœ… Keine\")\n",
    "print(\"ðŸ“ Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"âœ… Keine\")\n",
    "print(\"ðŸ“› Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"âœ… Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2a76",
   "metadata": {},
   "source": [
    "## Datensatz Hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ðŸ”¢ Gruppennummer eintragen\n",
    "gruppen_nummer = \"60\"  # z.â€¯B. \"01\", \"17\", \"60\"\n",
    "\n",
    "# ðŸ“‚ Lokaler Ordner mit den exportierten JSONs/Bildern\n",
    "target_dir = f\"datensatz_augmented\"\n",
    "\n",
    "# ðŸŒ Ziel: annotierte_daten innerhalb der Gruppenstruktur\n",
    "webdav_base = f\"https://mrzinken.duckdns.org/remote.php/dav/files/hackathon2025/HackathonBonn/Gruppe{gruppen_nummer}/annotierte_daten\"\n",
    "\n",
    "# ðŸ” Zugangsdaten\n",
    "username = \"hackathon2025\"\n",
    "password = \"upload2025\"\n",
    "\n",
    "# ðŸ“¤ Upload-Schleife\n",
    "for fname in tqdm(os.listdir(target_dir), desc=\"ðŸ“¤ Upload lÃ¤uft\"):\n",
    "    fpath = os.path.join(target_dir, fname)\n",
    "    if os.path.isfile(fpath):\n",
    "        remote_url = f\"{webdav_base}/{fname}\"\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            r = requests.put(remote_url, data=f, auth=(username, password))\n",
    "        if r.status_code in [200, 201, 204]:\n",
    "            print(f\"âœ… Hochgeladen: {fname}\")\n",
    "        else:\n",
    "            print(f\"âŒ Fehler bei {fname}: {r.status_code} {r.text}\")\n",
    "\n",
    "print(\"ðŸ Upload abgeschlossen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
