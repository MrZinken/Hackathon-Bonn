{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# üñºÔ∏è 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erh√§lt einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## üîß Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://databox.bonn.de/public/upload-shares/YhXlVGe57thQAg8WUjVlZFNK6z4LORiq) runter\n",
    "1. √ñffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Segmentation**\n",
    "4. Klasse: z.‚ÄØB. `baum`, `√ºberdachung`\n",
    "5. Export: Format `Pascal VOC Segmentation (PNG masks)`\n",
    "\n",
    "üëâ Jetzt bitte eure annotierten Masken und Bilder wieder hochladen. Verwende folgenden Platzhalter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Gruppennummer eintragen\n",
    "gruppen_nummer = 2\n",
    "\n",
    "# Arbeitsverzeichnis dynamisch zusammensetzen\n",
    "annotations_file = f\"datensatz_gruppe{gruppen_nummer}/annotations.json\"\n",
    "images_dir = f\"datensatz_gruppe{gruppen_nummer}\"\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(annotations_file)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Nimm das erste Bild\n",
    "img_id = image_ids[0]\n",
    "img_info = coco.loadImgs(img_id)[0]\n",
    "img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "# Bild laden\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Plot vorbereiten\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Annotations laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Maske zeichnen\n",
    "for ann in anns:\n",
    "    if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "        for seg in ann['segmentation']:\n",
    "            poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "plt.title(img_info['file_name'])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## üìà Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die Robustheit und Generalisierungsf√§higkeit des Modells zu verbessern, wurde der Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurde zu jedem bestehenden Bild **eine sinnvolle Transformation** erzeugt.\n",
    "\n",
    "Die angewendeten Augmentierungsschritte umfassen:\n",
    "- **Horizontales Spiegeln**\n",
    "- **Leichte Rotation (¬±15¬∞)**\n",
    "- **√Ñnderung von Helligkeit und Kontrast**\n",
    "\n",
    "F√ºr jedes Originalbild wurde ein neues Bild generiert. Die zugeh√∂rigen Segmentierungs-Masken wurden dabei korrekt mittransformiert. Die augmentierten Bilder und Masken wurden zusammen mit den Originalen in einer neuen COCO-kompatib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from pycocotools import mask as mask_utils\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# üìÇ Verzeichnisse\n",
    "source_dir = images_dir\n",
    "target_dir = f\"datensatz_gruppe{gruppen_nummer}_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# üìñ Originaldaten laden\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# üß± Neue COCO-Struktur ‚Üí beginne mit Kopie der Originale\n",
    "extended_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# Kopiere originale Bilder & √ºbernehme JSON-Eintr√§ge\n",
    "for img_entry in coco_data[\"images\"]:\n",
    "    src_path = os.path.join(source_dir, img_entry[\"file_name\"])\n",
    "    dst_path = os.path.join(target_dir, img_entry[\"file_name\"])\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    extended_data[\"images\"].append(img_entry)\n",
    "\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    extended_data[\"annotations\"].append(ann)\n",
    "\n",
    "# ID-Offsets\n",
    "next_image_id = max(img[\"id\"] for img in coco_data[\"images\"]) + 1\n",
    "next_ann_id = max(ann[\"id\"] for ann in coco_data[\"annotations\"]) + 1\n",
    "\n",
    "# Bild-ID ‚Üí Annotations\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# ‚úÖ Sichere Augmentierungen\n",
    "aug_choices = [\n",
    "    (\"flipH\", A.HorizontalFlip(p=1.0)),\n",
    "    (\"flipV\", A.VerticalFlip(p=1.0)),\n",
    "    (\"rot90\", A.RandomRotate90(p=1.0))\n",
    "]\n",
    "\n",
    "# Augmentieren\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    aug_name, transform = random.choice(aug_choices)\n",
    "    transformed = transform(image=img, masks=masks)\n",
    "    aug_img = transformed[\"image\"]\n",
    "    aug_masks = transformed[\"masks\"]\n",
    "\n",
    "    new_filename = f\"{aug_name}_{file_name}\"\n",
    "    new_img_path = os.path.join(target_dir, new_filename)\n",
    "    cv2.imwrite(new_img_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    extended_data[\"images\"].append({\n",
    "        \"id\": next_image_id,\n",
    "        \"file_name\": new_filename,\n",
    "        \"width\": aug_img.shape[1],\n",
    "        \"height\": aug_img.shape[0]\n",
    "    })\n",
    "\n",
    "    for mask in aug_masks:\n",
    "        rle = mask_utils.encode(np.asfortranarray(mask.astype(np.uint8)))\n",
    "        area = mask_utils.area(rle).item()\n",
    "        bbox = mask_utils.toBbox(rle).tolist()\n",
    "\n",
    "        seg = mask_utils.encode(np.asfortranarray(mask))\n",
    "        seg[\"counts\"] = seg[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "        extended_data[\"annotations\"].append({\n",
    "            \"id\": next_ann_id,\n",
    "            \"image_id\": next_image_id,\n",
    "            \"category_id\": 1,\n",
    "            \"segmentation\": seg,\n",
    "            \"area\": area,\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": 0\n",
    "        })\n",
    "        next_ann_id += 1\n",
    "\n",
    "    next_image_id += 1\n",
    "\n",
    "# Speichern\n",
    "json_out = os.path.join(target_dir, \"annotations_augmented.json\")\n",
    "with open(json_out, \"w\") as f:\n",
    "    json.dump(extended_data, f)\n",
    "\n",
    "print(f\"‚úÖ Erweiterung abgeschlossen. Gesamt-Datensatz unter: {target_dir}, JSON: {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# Pfade\n",
    "json_path = f\"{target_dir}/annotations_augmented.json\"\n",
    "img_dir = target_dir\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(json_path)\n",
    "images = coco.dataset[\"images\"]\n",
    "\n",
    "# üìå Nur augmentierte Bilder ausw√§hlen (z.‚ÄØB. \"flipH_\", \"flipV_\", \"rot90_\")\n",
    "aug_images = [img for img in images if img[\"file_name\"].startswith((\"flip\", \"rot\", \"flipH\", \"flipV\"))]\n",
    "\n",
    "# Erstes augmentiertes Bild\n",
    "img_info = aug_images[0]\n",
    "img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Masken laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_info[\"id\"])\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "for ann in anns:\n",
    "    seg = ann[\"segmentation\"]\n",
    "    \n",
    "    if isinstance(seg, list):  # Polygon\n",
    "        for s in seg:\n",
    "            poly = np.array(s).reshape((len(s) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "    elif isinstance(seg, dict) and \"counts\" in seg:  # RLE\n",
    "        rle = {\n",
    "            \"counts\": seg[\"counts\"].encode(\"utf-8\"),\n",
    "            \"size\": seg[\"size\"]\n",
    "        }\n",
    "        mask = mask_utils.decode(rle)\n",
    "        ax.contour(mask, colors='red', linewidths=2)\n",
    "\n",
    "ax.set_title(f\"Augmentiertes Bild: {img_info['file_name']}\")\n",
    "ax.axis(\"off\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz pr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# üìñ JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# üîé Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# üîé Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# üîé IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# ‚úÖ Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# üñ®Ô∏è Ergebnis\n",
    "print(\"üìÅ Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"‚úÖ Keine\")\n",
    "print(\"üìÅ Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"‚úÖ Keine\")\n",
    "print(\"üìõ Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"‚úÖ Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae2a76",
   "metadata": {},
   "source": [
    "## Datensatz Hochladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "target_dir = f\"datensatz_gruppe{gruppen_nummer}_augmented\"\n",
    "\n",
    "# üåê WebDAV-Ziel ohne abschlie√üenden Slash!\n",
    "webdav_base = f\"https://mrzinken.duckdns.org/remote.php/dav/files/hackathon2025/HackathonBonn/gruppe{gruppen_nummer}\"\n",
    "\n",
    "# üîê Zugangsdaten\n",
    "username = \"hackathon2025\"\n",
    "password = getpass(\"üîë Passwort eingeben:\")\n",
    "\n",
    "# üì§ Upload-Schleife\n",
    "for fname in tqdm(os.listdir(target_dir), desc=\"üì§ Upload l√§uft\"):\n",
    "    fpath = os.path.join(target_dir, fname)\n",
    "    if os.path.isfile(fpath):\n",
    "        remote_url = f\"{webdav_base}/{fname}\"\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            r = requests.put(remote_url, data=f, auth=(username, password))\n",
    "        if r.status_code in [200, 201, 204]:\n",
    "            print(f\"‚úÖ Hochgeladen: {fname}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Fehler bei {fname}: {r.status_code} {r.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
