{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fd9e29",
   "metadata": {},
   "source": [
    "# 🖼️ 1. Datensatz vorbereiten\n",
    "\n",
    "Jede Gruppe erhält einen Ordner mit **Rohbildern**. Diese sollen in [Makesense.ai](https://www.makesense.ai) annotiert werden.\n",
    "\n",
    "## 🔧 Schritt 1: Annotation mit Makesense.ai\n",
    "0. Ladet die Rohbilder mit eurer Gruppennummer unter folgender [URL](https://databox.bonn.de/public/upload-shares/YhXlVGe57thQAg8WUjVlZFNK6z4LORiq) runter\n",
    "1. Öffnet [https://www.makesense.ai](https://www.makesense.ai)\n",
    "2. Bilder hochladen\n",
    "3. Modus: **Segmentation**\n",
    "4. Klasse: z. B. `baum`, `überdachung`\n",
    "5. Export: Format `Pascal VOC Segmentation (PNG masks)`\n",
    "\n",
    "👉 Jetzt bitte eure annotierten Masken und Bilder wieder hochladen. Verwende folgenden Platzhalter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Für stabile Anzeige in JupyterLab\n",
    "from IPython.display import display\n",
    "\n",
    "# Arbeitsverzeichnis\n",
    "annotations_file = \"datensatz_gruppe1/annotations.json\"\n",
    "images_dir = \"datensatz_gruppe1\"\n",
    "\n",
    "# COCO laden\n",
    "coco = COCO(annotations_file)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Nimm das erste Bild\n",
    "img_id = image_ids[0]\n",
    "img_info = coco.loadImgs(img_id)[0]\n",
    "img_path = os.path.join(images_dir, img_info['file_name'])\n",
    "\n",
    "# Bild laden\n",
    "image = Image.open(img_path)\n",
    "\n",
    "# Plot vorbereiten\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Annotations laden\n",
    "ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Maske zeichnen\n",
    "for ann in anns:\n",
    "    if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
    "        for seg in ann['segmentation']:\n",
    "            poly = np.array(seg).reshape((len(seg) // 2, 2))\n",
    "            patch = patches.Polygon(poly, fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "plt.title(img_info['file_name'])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71a73",
   "metadata": {},
   "source": [
    "## 📈 Datensatz-Erweiterung durch Augmentation\n",
    "\n",
    "Um die Robustheit und Generalisierungsfähigkeit des Modells zu verbessern, wurde der Datensatz durch gezielte Bildaugmentierung erweitert. Dabei wurde zu jedem bestehenden Bild **eine sinnvolle Transformation** erzeugt.\n",
    "\n",
    "Die angewendeten Augmentierungsschritte umfassen:\n",
    "- **Horizontales Spiegeln**\n",
    "- **Leichte Rotation (±15°)**\n",
    "- **Änderung von Helligkeit und Kontrast**\n",
    "\n",
    "Für jedes Originalbild wurde ein neues Bild generiert. Die zugehörigen Segmentierungs-Masken wurden dabei korrekt mittransformiert. Die augmentierten Bilder und Masken wurden zusammen mit den Originalen in einer neuen COCO-kompatib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pycocotools import mask as mask_utils\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 📂 Verzeichnisse\n",
    "source_dir = \"datensatz_gruppe1\"\n",
    "target_dir = \"datensatz_gruppe1_augmented\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# 📖 Originaldaten laden\n",
    "with open(os.path.join(source_dir, \"annotations.json\"), \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Neue COCO-Struktur\n",
    "aug_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": coco_data[\"categories\"]\n",
    "}\n",
    "\n",
    "# ID-Offsets\n",
    "next_image_id = 10000\n",
    "next_ann_id = 50000\n",
    "\n",
    "# Bild-ID → Annotations\n",
    "img_to_anns = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_to_anns.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "\n",
    "# ✅ Nur sichere Augmentierungen (keine schwarzen Ränder)\n",
    "transform_options = [\n",
    "    (\"flipH\", A.HorizontalFlip(p=1.0)),\n",
    "    (\"flipV\", A.VerticalFlip(p=1.0)),\n",
    "    (\"rot90\", A.RandomRotate90(p=1.0))\n",
    "]\n",
    "\n",
    "for img_entry in tqdm(coco_data[\"images\"], desc=\"Augmentiere Bilder\"):\n",
    "    file_name = img_entry[\"file_name\"]\n",
    "    img_path = os.path.join(source_dir, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    anns = img_to_anns.get(img_entry[\"id\"], [])\n",
    "    if not anns:\n",
    "        continue\n",
    "\n",
    "    # Segmentierungen → Masken\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [pts.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "    # ✅ Augmentation auswählen\n",
    "    aug_name, transform = A.OneOf([\n",
    "        (A.HorizontalFlip(p=1.0), 1),\n",
    "        (A.VerticalFlip(p=1.0), 1),\n",
    "        (A.RandomRotate90(p=1.0), 1),\n",
    "    ], p=1.0)(image=img, masks=masks).items()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20c3",
   "metadata": {},
   "source": [
    "## Visualisierung der Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 🔧 Pfade anpassen\n",
    "image_dir = \"datensatz_gruppe1_extended\"\n",
    "json_path = os.path.join(image_dir, \"annotations_extended.json\")\n",
    "\n",
    "# 📖 JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 🔎 Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# 🔎 Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# 🔎 IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# ✅ Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# 🖨️ Ergebnis\n",
    "print(\"📁 Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"✅ Keine\")\n",
    "print(\"📁 Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"✅ Keine\")\n",
    "print(\"📛 Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"✅ Keine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93415f",
   "metadata": {},
   "source": [
    "## Datensatz prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f907670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 🔧 Pfade anpassen\n",
    "image_dir = \"datensatz_gruppe1_extended\"\n",
    "json_path = os.path.join(image_dir, \"annotations_extended.json\")\n",
    "\n",
    "# 📖 JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 🔎 Bildnamen aus JSON\n",
    "json_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "json_image_ids = {img[\"id\"] for img in data[\"images\"]}\n",
    "\n",
    "# 🔎 Bilddateien im Ordner\n",
    "folder_images = {f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".png\"))}\n",
    "\n",
    "# 🔎 IDs aus Annotations\n",
    "referenced_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "# ✅ Checks\n",
    "missing_files = json_images - folder_images\n",
    "unreferenced_files = folder_images - json_images\n",
    "annotations_without_images = referenced_ids - json_image_ids\n",
    "\n",
    "# 🖨️ Ergebnis\n",
    "print(\"📁 Bilder in JSON, aber nicht im Ordner:\", missing_files if missing_files else \"✅ Keine\")\n",
    "print(\"📁 Bilder im Ordner, aber nicht in JSON:\", unreferenced_files if unreferenced_files else \"✅ Keine\")\n",
    "print(\"📛 Annotations mit fehlenden Bild-IDs:\", annotations_without_images if annotations_without_images else \"✅ Keine\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
